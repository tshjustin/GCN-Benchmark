{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining reddit_data.npz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of reddit_data: ['feature', 'node_types', 'node_ids', 'label']\n"
     ]
    }
   ],
   "source": [
    "data = np.load('reddit/reddit_data.npz')\n",
    "print(\"Columns of reddit_data:\", data.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (232965, 602)\n",
      "Node types shape: (232965,)\n",
      "Node IDs shape: (232965,)\n",
      "Labels shape: (232965,)\n"
     ]
    }
   ],
   "source": [
    "features = data['feature'] \n",
    "node_types = data['node_types'] \n",
    "node_ids = data['node_ids']\n",
    "labels = data['label']  \n",
    "\n",
    "print(\"Features shape:\", features.shape)\n",
    "print(\"Node types shape:\", node_types.shape)\n",
    "print(\"Node IDs shape:\", node_ids.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10 features:\n",
      "[[ 1.23341458  9.04301168 -0.92328005 ... -0.2578954   0.31119258\n",
      "  -0.37721241]\n",
      " [-0.13855163 -0.20221879  0.12771628 ...  0.15627094  0.10478096\n",
      "  -0.65342009]\n",
      " [-0.13304173 -0.1962387  -0.02956016 ...  0.03580163  0.28636732\n",
      "   0.27441325]\n",
      " ...\n",
      " [-0.13855163 -0.20520884 -2.05916421 ...  0.08524973  0.65964959\n",
      "  -0.2079452 ]\n",
      " [-0.15508134 -0.19922874  4.0886282  ... -0.1134238  -0.14133508\n",
      "   0.58370981]\n",
      " [-0.15508134 -0.20221879  0.93078404 ... -0.60601635  3.21872952\n",
      "  -0.83696218]]\n",
      "\n",
      " 10 node types:\n",
      "[3 1 3 1 1 2 1 2 1 1]\n",
      "\n",
      " 10 node IDs:\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      " 10 labels:\n",
      "[30 17 18 23 22 15 33 14 38 18]\n"
     ]
    }
   ],
   "source": [
    "print(\" 10 features:\")\n",
    "print(features[:10])\n",
    "\n",
    "print(\"\\n 10 node types:\")\n",
    "print(node_types[:10])\n",
    "\n",
    "print(\"\\n 10 node IDs:\")\n",
    "print(node_ids[:10])\n",
    "\n",
    "print(\"\\n 10 labels:\")\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node type distribution: {1: 153431, 2: 23831, 3: 55703}\n",
      "Label distribution: {0: 13101, 1: 3550, 2: 3302, 3: 15181, 4: 2322, 5: 3597, 6: 3952, 7: 2138, 8: 11187, 9: 2246, 10: 4928, 11: 2964, 12: 1696, 13: 2731, 14: 4854, 15: 28272, 16: 1003, 17: 2639, 18: 13999, 19: 10308, 20: 1596, 21: 4066, 22: 8222, 23: 12146, 24: 328, 25: 1659, 26: 4239, 27: 5962, 28: 4673, 29: 5101, 30: 2846, 31: 4570, 32: 1575, 33: 4960, 34: 3429, 35: 4202, 36: 4180, 37: 4233, 38: 12797, 39: 3099, 40: 5112}\n"
     ]
    }
   ],
   "source": [
    "unique_types, counts = np.unique(node_types, return_counts=True)\n",
    "print(\"Node type distribution:\", dict(zip(unique_types, counts)))\n",
    "\n",
    "unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "print(\"Label distribution:\", dict(zip(unique_labels, label_counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features of Reddit_Data\n",
    "\n",
    "Features shape: (232965, 602): 232,965 Nodes with 602 features each \n",
    "\n",
    "Node IDs shape: Each Node have a unique ID \n",
    "\n",
    "Label distribution: Number of nodes in each label class (40 Classes in total)\n",
    "\n",
    "### Examining reddit_graph.npz\n",
    "This contains the structure of the graph - Represent it as a sparse matrix and examine the connectedness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of reddit_graph: ['format', 'col', 'data', 'shape', 'row']\n"
     ]
    }
   ],
   "source": [
    "graph_data = np.load('reddit/reddit_graph.npz')\n",
    "\n",
    "print(\"Columns of reddit_graph:\", graph_data.files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = graph_data['row']\n",
    "col = graph_data['col']\n",
    "data_values = graph_data['data']\n",
    "shape = tuple(graph_data['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse matrix shape: (232965, 232965)\n",
      "Number of non-zero elements: 114615892\n",
      "Matrix density: 0.002111852009048774\n"
     ]
    }
   ],
   "source": [
    "sparse_matrix = coo_matrix((data_values, (row, col)), shape=shape)\n",
    "\n",
    "print(\"Sparse matrix shape:\", sparse_matrix.shape)\n",
    "print(\"Number of non-zero elements:\", sparse_matrix.nnz)\n",
    "\n",
    "density = sparse_matrix.nnz / (sparse_matrix.shape[0] * sparse_matrix.shape[1]) # check number of non-zero / total entries \n",
    "print(\"Matrix density:\", density)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reddit_graph(sparse_matrix):\n",
    "    \"\"\"Creates Reddit Graph from the sparse matrix \"\"\"\n",
    "    G = nx.Graph()\n",
    "    row, col = sparse_matrix.row, sparse_matrix.col\n",
    "    \n",
    "    edges = list(zip(row, col))\n",
    "    G.add_edges_from(edges)  \n",
    "    \n",
    "    return G\n",
    "\n",
    "def visualize_reddit_graph(G, labels):\n",
    "    \"\"\"Visualizes Reddit Graph with Class Labels\"\"\"\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    nx.draw(G, pos, node_size=10, node_color='blue', edge_color='gray', with_labels=False)\n",
    "    \n",
    "    nx.draw_networkx_labels(G, pos, labels, font_size=8, font_color='red')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232965\n",
      "number unique labels: 41\n"
     ]
    }
   ],
   "source": [
    "# Create the label dictionary \n",
    "reddit_labels = {node_ids[i]: labels[i] for i in range(len(node_ids))}\n",
    "\n",
    "print(len(reddit_labels)) # number of nodes \n",
    "\n",
    "unique_labels = set(labels)\n",
    "print(\"number unique labels:\", len(unique_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = create_reddit_graph(sparse_matrix)\n",
    "\n",
    "visualize_reddit_graph(G, reddit_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
